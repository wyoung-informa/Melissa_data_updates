{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "import psycopg2 as p\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = '*****'\n",
    "\n",
    "conn = p.connect(database = 'postgres', user = 'postgres', password = password, \n",
    "                       host = 'localhost', port = 5433)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"select fs_fleet_id, company_name, mcmis_phy_address, mcmis_mai_address, mcmis_tel_num, differences, uniform_mcmis_address from fleetseek.updates_bn_coder_output\")\n",
    "rows = cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Different calls based on the difference in the FS address and MCMIS addresses given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "# Physical addresses and if both are different but the MCMIS address is the same then only needs to be sent through once\n",
    "\n",
    "\n",
    "phy_add = []\n",
    "\n",
    "\n",
    "with requests.Session() as s:\n",
    "    \n",
    "    for index, data in enumerate(rows):\n",
    "        if data[5] == 'physical' or (data[5] == 'both' and data[6] == True):\n",
    "            \n",
    "            r = s.get(\"\"\"https://businesscoder.melissadata.net/WEB/BusinessCoder/doBusinessCoderUS?id=F2xsYwygKO1EfNo3Ppd335**&cols=GrpCensus,GrpGeoCode,GrpBusinessCodes, \n",
    "    GrpAddressDetails,GrpBusinessDescription,Contacts&comp=\"\"\" +data[1]+\"\"\"&a1=\"\"\"+data[2]+\"\"\"&phone=\"\"\"+str(data[4]))\n",
    "            phy_info = r.json()\n",
    "\n",
    "            phy_add.append([phy_info, {'index_number':index, 'difference':data[5], 'mcmis_address':data[6], 'fleet_id':data[0]}])\n",
    "        else:\n",
    "            continue\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "# Just mailing \n",
    "\n",
    "mai_add = []\n",
    "\n",
    "\n",
    "with requests.Session() as s:\n",
    "    \n",
    "    for index, data in enumerate(rows):\n",
    "        if data[5] == 'mailing':\n",
    "            \n",
    "            r = s.get(\"\"\"https://businesscoder.melissadata.net/WEB/BusinessCoder/doBusinessCoderUS?id=F2xsYwygKO1EfNo3Ppd335**&cols=GrpCensus,GrpGeoCode,GrpBusinessCodes, \n",
    "    GrpAddressDetails,GrpBusinessDescription,Contacts&comp=\"\"\" +data[1]+\"\"\"&a1=\"\"\"+data[3]+\"\"\"&phone=\"\"\"+str(data[4]))\n",
    "            mai_info = r.json()\n",
    "\n",
    "            mai_add.append([mai_info, {'index_number':index, 'difference':data[5], 'mcmis_address':data[6], 'fleet_id':data[0]}])\n",
    "        else:\n",
    "            continue\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "# Both and false, this one will need to be sent through twice to look at differences\n",
    "\n",
    "combined_phy = []\n",
    "combined_mai = []\n",
    "\n",
    "with requests.Session() as s:\n",
    "    \n",
    "    for index, data in enumerate(rows):\n",
    "    \n",
    "        if data[5] == 'both' and data[6] == False:\n",
    "\n",
    "            \n",
    "            # Index 2 is for the physical address\n",
    "            r = s.get(\"\"\"https://businesscoder.melissadata.net/WEB/BusinessCoder/doBusinessCoderUS?id=F2xsYwygKO1EfNo3Ppd335**&cols=GrpCensus,GrpGeoCode,GrpBusinessCodes, \n",
    "                     GrpAddressDetails,GrpBusinessDescription,Contacts&comp=\"\"\" +data[1]+\"\"\"&a1=\"\"\"+data[2]+\"\"\"&phone=\"\"\"+str(data[4]))\n",
    "            phy_info = r.json()\n",
    "            \n",
    "            \n",
    "            # Adds the index, the difference, and whether the mcmis addresses are uniform\n",
    "            combined_phy.append([phy_info, {'index_number': index, 'difference':data[5], 'mcmis_address':data[6], 'fleet_id':data[0]}])\n",
    "\n",
    "\n",
    "            # Index 3 is for mailing address\n",
    "            t = s.get(\"\"\"https://businesscoder.melissadata.net/WEB/BusinessCoder/doBusinessCoderUS?id=F2xsYwygKO1EfNo3Ppd335**&cols=GrpCensus,GrpGeoCode,GrpBusinessCodes, \n",
    "                     GrpAddressDetails,GrpBusinessDescription,Contacts&comp=\"\"\" +data[1]+\"\"\"&a1=\"\"\"+data[3]+\"\"\"&phone=\"\"\"+str(data[4]))\n",
    "\n",
    "            mai_info = t.json()\n",
    "            \n",
    "            # Adds the index, the difference, and whether the mcmis addresses are uniform\n",
    "            combined_mai.append([mai_info, {'index_number': index, 'difference':data[5], 'mcmis_address':data[6], 'fleet_id':data[0]}])\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phy_add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformatting all dataframes to have a uniform layout to insert into PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(columns = ['fs_fleet_id', 'index_number', 'address_difference', 'uniform_mcmis_address', 'company_name', 'phy_address', 'phy_city', 'phy_countyfips', \n",
    "                              'phy_countyname', 'phy_state','phy_latitude', 'phy_longitude', 'phy_zip_code', 'phy_suite', 'phy_result_codes', 'mai_address', 'mai_city', \n",
    "                              'mai_countyfips', 'mai_countyname', 'mai_state','mai_latitude', 'mai_longitude', 'mai_zip_code', 'mai_suite', 'mai_result_codes'])\n",
    "\n",
    "for index, info in enumerate(phy_add):\n",
    "    \n",
    "    \n",
    "    list_index = info[1]['index_number']\n",
    "    difference = info[1]['difference']\n",
    "    mcmis_addresses = info[1]['mcmis_address']\n",
    "    fleet_id = info[1]['fleet_id']\n",
    "    phy_city = info[0]['Records'][0]['City']\n",
    "    company_name = info[0]['Records'][0]['CompanyName']\n",
    "    a1 = info[0]['Records'][0]['AddressLine1']\n",
    "    phy_state = info[0]['Records'][0]['State']\n",
    "    phy_countyfips = info[0]['Records'][0]['CountyFIPS']\n",
    "    phy_countyname = info[0]['Records'][0]['CountyName']\n",
    "    phy_latitude = info[0]['Records'][0]['Latitude']\n",
    "    phy_longitude = info[0]['Records'][0]['Longitude']\n",
    "    phy_zip_code = info[0]['Records'][0]['PostalCode']\n",
    "    phy_suite = info[0]['Records'][0]['Suite']\n",
    "    phy_result_codes = info[0]['Records'][0]['Results']\n",
    "    \n",
    "    \n",
    "    \n",
    "    if difference == 'both' and mcmis_addresses == True:\n",
    "        df1 = df1.append({'index_number':list_index, 'address_difference':difference, 'uniform_mcmis_address':mcmis_addresses, 'fs_fleet_id':fleet_id, 'company_name':company_name, \n",
    "                      'phy_city':phy_city, 'phy_countyfips':phy_countyfips, 'phy_countyname':phy_countyname, 'phy_latitude':phy_latitude, 'phy_longitude':phy_longitude, \n",
    "                      'phy_zip_code': phy_zip_code, 'phy_result_codes':phy_result_codes, 'mai_city':phy_city, 'mai_countyfips':phy_countyfips, \n",
    "                      'mai_countyname':phy_countyname, 'mai_latitude':phy_latitude, 'mai_longitude':phy_longitude, 'mai_zip_code': phy_zip_code, 'phy_address':a1, \n",
    "                      'phy_suite':phy_suite, 'mai_address':a1, 'mai_suite':phy_suite, 'mai_result_codes':phy_result_codes, 'phy_state':phy_state, \n",
    "                      'mai_state':phy_state}, ignore_index = True)\n",
    "        \n",
    "    else:\n",
    "        df1 = df1.append({'index_number':list_index, 'address_difference':difference, 'uniform_mcmis_address':mcmis_addresses, 'fs_fleet_id':fleet_id, 'company_name':company_name, \n",
    "                          'phy_city':phy_city, 'phy_countyfips':phy_countyfips, 'phy_countyname':phy_countyname, 'phy_latitude':phy_latitude, 'phy_longitude':phy_longitude, \n",
    "                          'phy_zip_code': phy_zip_code, 'phy_result_codes':phy_result_codes, 'mai_city':np.nan, 'mai_countyfips':np.nan, \n",
    "                          'mai_countyname':np.nan, 'mai_latitude':np.nan, 'mai_longitude':np.nan, 'mai_zip_code': np.nan, 'phy_address':a1, 'phy_suite':phy_suite, \n",
    "                          'mai_address':np.nan, 'mai_suite':np.nan, 'mai_result_codes':np.nan, 'phy_state':phy_state, 'mai_state':np.nan}, ignore_index = True)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2 = pd.DataFrame(columns = ['fs_fleet_id', 'index_number', 'address_difference', 'uniform_mcmis_address', 'company_name', 'phy_address', 'phy_city', 'phy_countyfips', \n",
    "                              'phy_countyname', 'phy_state', 'phy_latitude', 'phy_longitude', 'phy_zip_code', 'phy_suite', 'phy_result_codes', 'mai_address','mai_city', \n",
    "                              'mai_countyfips', 'mai_countyname', 'mai_state', 'mai_latitude', 'mai_longitude', 'mai_zip_code', 'mai_suite', 'mai_result_codes'])\n",
    "\n",
    "for index, info in enumerate(mai_add):\n",
    "\n",
    "    list_index = info[1]['index_number']\n",
    "    difference = info[1]['difference']\n",
    "    mcmis_address = info[1]['mcmis_address']\n",
    "    fleet_id = info[1]['fleet_id']\n",
    "    mai_city = info[0]['Records'][0]['City']\n",
    "    company_name = info[0]['Records'][0]['CompanyName']\n",
    "    a1 = info[0]['Records'][0]['AddressLine1']\n",
    "    mai_state = info[0]['Records'][0]['State']\n",
    "    mai_countyfips = info[0]['Records'][0]['CountyFIPS']\n",
    "    mai_countyname = info[0]['Records'][0]['CountyName']\n",
    "    mai_latitude = info[0]['Records'][0]['Latitude']\n",
    "    mai_longitude = info[0]['Records'][0]['Longitude']\n",
    "    mai_zip_code = info[0]['Records'][0]['PostalCode']\n",
    "    mai_suite = info[0]['Records'][0]['Suite']\n",
    "    mai_result_codes = info[0]['Records'][0]['Results']\n",
    "    \n",
    "    df2 = df2.append({'index_number':list_index, 'address_difference':difference, 'uniform_mcmis_address':mcmis_addresses, 'fs_fleet_id':fleet_id, 'company_name':company_name, \n",
    "                      'phy_city':np.nan, 'phy_countyfips':np.nan, 'phy_countyname':np.nan, 'phy_latitude':np.nan, 'phy_longitude':np.nan, \n",
    "                      'phy_zip_code': np.nan, 'phy_result_codes':np.nan, 'mai_city':mai_city, 'mai_countyfips':mai_countyfips, 'mai_address':a1,\n",
    "                      'mai_countyname':mai_countyname, 'mai_latitude':mai_latitude, 'mai_longitude':mai_longitude, 'mai_zip_code': mai_zip_code, 'phy_address':np.nan, \n",
    "                      'mai_suite': mai_suite, 'phy_suite':np.nan, 'mai_result_codes':mai_result_codes, 'phy_state':np.nan, 'mai_state':mai_state}, ignore_index = True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(columns = ['fs_fleet_id', 'index_number', 'address_difference', 'uniform_mcmis_address', 'company_name', 'phy_address', 'phy_city', 'phy_countyfips', \n",
    "                              'phy_countyname', 'phy_state', 'phy_latitude', 'phy_longitude', 'phy_zip_code', 'phy_suite', 'phy_result_codes', 'mai_address','mai_city', \n",
    "                              'mai_countyfips', 'mai_countyname', 'mai_state',  'mai_latitude', 'mai_longitude', 'mai_zip_code', 'mai_suite', 'mai_result_codes'])\n",
    "\n",
    "\n",
    "# zip is used for lists of same length \n",
    "for info in zip(combined_phy, combined_mai):\n",
    "\n",
    "    list_index = info[0][1]['index_number']\n",
    "    difference = info[0][1]['difference']\n",
    "    mcmis_addresses = info[0][1]['mcmis_address']\n",
    "    fleet_id = info[1]['fleet_id']\n",
    "    company_name = info[0][0]['Records'][0]['CompanyName']\n",
    "    a1 = info[0]['Records'][0]['AddressLine1']\n",
    "    phy_state = info[0]['Records'][0]['State']\n",
    "    phy_city = info[0][0]['Records'][0]['City']\n",
    "    phy_countyfips = info[0][0]['Records'][0]['CountyFIPS']\n",
    "    phy_countyname = info[0][0]['Records'][0]['CountyName']\n",
    "    phy_latitude = info[0][0]['Records'][0]['Latitude']\n",
    "    phy_longitude = info[0][0]['Records'][0]['Longitude']\n",
    "    phy_zip_code = info[0][0]['Records'][0]['PostalCode']\n",
    "    phy_suite = info[0][0]['Records'][0]['Suite']\n",
    "    phy_result_codes = info[0][0]['Records'][0]['Results']\n",
    "    a2 = info[1][0]['Records'][0]['AddressLine1']\n",
    "    mai_city = info[1][0]['Records'][0]['City']\n",
    "    mai_state = info[1][0]['Records'][0]['State']\n",
    "    mai_countyfips = info[1][0]['Records'][0]['CountyFIPS']\n",
    "    mai_countyname = info[1][0]['Records'][0]['CountyName']\n",
    "    mai_latitude = info[1][0]['Records'][0]['Latitude']\n",
    "    mai_longitude = info[1][0]['Records'][0]['Longitude']\n",
    "    mai_zip_code = info[1][0]['Records'][0]['PostalCode']\n",
    "    mai_suite = info[1][0]['Records'][0]['Suite']\n",
    "    mai_result_codes = info[1][0]['Records'][0]['Results']\n",
    "    \n",
    "    df3 = df3.append({'index_number':list_index, 'address_difference':difference, 'uniform_mcmis_address':mcmis_addresses, 'fs_fleet_id':fleet_id, 'company_name':company_name, \n",
    "                      'phy_city':phy_city, 'phy_countyfips':phy_countyfips, 'phy_countyname':phy_countyname, 'phy_latitude':phy_latitude, 'phy_longitude':phy_longitude, \n",
    "                      'phy_zip_code': phy_zip_code, 'phy_result_codes':phy_result_codes, 'mai_city':mai_city, 'mai_countyfips':mai_countyfips, 'phy_address':a1, 'phy_suite':phy_suite,\n",
    "                      'mai_countyname':mai_countyname, 'mai_latitude':mai_latitude, 'mai_longitude':mai_longitude, 'mai_zip_code': mai_zip_code, 'mai_address':a2, \n",
    "                      'mai_suite':mai_suite,'mai_result_codes':mai_result_codes, 'phy_state':phy_state, 'mai_state':mai_state}, ignore_index = True)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.concat([df1, df2, df3])\n",
    "df4.drop(columns = 'index_number', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['phy_countyfips'].replace('', value = np.nan, inplace = True)\n",
    "df4['mai_countyfips'].replace('', value = np.nan, inplace = True)\n",
    "df4['phy_latitude'].replace('', value = np.nan, inplace = True)\n",
    "df4['phy_longitude'].replace('', value = np.nan, inplace = True)\n",
    "df4['mai_latitude'].replace('', value = np.nan, inplace = True)\n",
    "df4['mai_longitude'].replace('', value = np.nan, inplace = True)\n",
    "df4['phy_address'].replace('', value = np.nan, inplace = True)\n",
    "df4['phy_city'].replace('', value = np.nan, inplace = True)\n",
    "df4['phy_countyname'].replace('', value = np.nan, inplace = True)\n",
    "df4['mai_address'].replace('', value = np.nan, inplace = True)\n",
    "df4['mai_city'].replace('', value = np.nan, inplace = True)\n",
    "df4['mai_countyname'].replace('', value = np.nan, inplace = True)\n",
    "df4['phy_suite'].replace('', value = np.nan, inplace = True)\n",
    "df4['phy_zip_code'].replace('', value = np.nan, inplace = True)\n",
    "df4['mai_suite'].replace('', value = np.nan, inplace = True)\n",
    "df4['mai_zip_code'].replace('', value = np.nan, inplace = True)\n",
    "df4['phy_state'].replace('', value = np.nan, inplace = True)\n",
    "df4['mai_state'].replace('', value = np.nan, inplace = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"postgresql://{user}:{pw}@localhost:5433/{db}\"\n",
    "                      .format(user = 'postgres',\n",
    "                             pw = '*****',\n",
    "                             db = 'postgres'))\n",
    "\n",
    "df4.to_sql('updates_bn_coder_input', con = engine, if_exists='append', schema='fleetseek', index=False, chunksize = 1000, method = 'multi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
